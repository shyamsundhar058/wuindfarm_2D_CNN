# -*- coding: utf-8 -*-
"""Copy of 2nd_Dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WNbGQi2DlrHEXgFPWAxSSBRak1hXLU2I
"""

import pandas as pd

train = pd.read_excel("Simulation Measurement_2nd dataset.xlsx", header=None, sheet_name="Measurements", usecols=[19,23], names=['Time', 'current1'], engine='openpyxl')

import pandas as pd

test = pd.read_excel("Simulation Measurements.xlsx", header=None, sheet_name="Measurements 1", usecols=[0,4], names=['Time', 'current1'], engine='openpyxl')

train

test

segment_2_0_to_2_1 = train[(train['Time'] >= 5.0) & (train['Time'] <= 5.1)]
data = train[(train['Time'] < 5.0) | (train['Time'] > 5.1)]

data[(data['Time'] >= 5.0) & (data['Time'] <= 5.1)]

segment_2_0_to_2_1

data

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time
# Define the number of data points per segment
start=time.time()

sampling_rate = 30
num_images = 15 * 30
store=num_images
data_points_per_segment = 300001// num_images
num_images=len(data)//data_points_per_segment
# Create an empty DataFrame for storing the labels
labels_df = pd.DataFrame(columns=['Image_name','label'])

# Define the time range for oscillation
oscillation_start_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2, unit='s')
oscillation_end_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2.2, unit='s')


# Calculate the number of segments
for i in range(num_images):
    # Extract the segment of data
    segment = data.iloc[i * data_points_per_segment: (i + 1) * data_points_per_segment]

    # Separate the current channels
    current1 = segment['current1']
    label="normal"

    image_name=f'image_{i+1}.png'
    # Append the label to the labels DataFrame
    labels_data = {'label': [label], 'Image_name': [image_name]}
    new_entry = pd.DataFrame(labels_data)
    labels_df = pd.concat([labels_df, new_entry], ignore_index=True)
    # Plot and save the image
    plt.plot(current1, 'k')
    plt.axis('off')
    plt.savefig(f'2nd/image_{i+1}.png', bbox_inches='tight', pad_inches=0)
    plt.clf()

# Print the resulting DataFrame with labels
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time
# Define the number of data points per segment
sampling_rate = 30
num_images = 15 * 30
store=num_images
data_points_per_segment = 300001// num_images
num_images=len(segment_2_0_to_2_1)//data_points_per_segment
# Create an empty DataFrame for storing the labels
#labels_df = pd.DataFrame(columns=['Image_name','label'])

# Define the time range for oscillation
oscillation_start_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2, unit='s')
oscillation_end_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2.2, unit='s')

j=448
# Calculate the number of segments
for i in range(num_images):
    # Extract the segment of data
    segment = segment_2_0_to_2_1.iloc[i * data_points_per_segment: (i + 1) * data_points_per_segment]

    # Separate the current channels
    current1 = segment['current1']
    label="oscillated"

    image_name=f'image_{j}.png'
    labels_data = {'label': [label], 'Image_name': [image_name]}
    new_entry = pd.DataFrame(labels_data)
    labels_df = pd.concat([labels_df, new_entry], ignore_index=True)

    # Plot and save the image
    plt.plot(current1, 'k')
    plt.axis('off')
    plt.show()
    plt.savefig(f'2nd/image_{j}.png', bbox_inches='tight', pad_inches=0)
    plt.clf()
    j+=1
# Print the resulting DataFrame with labels
print(labels_df)
print("train segmentation time",time.time()-start)

import cv2
import os
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle

# Define the directory where the images are stored
image_dir = '2nd'

# Get the list of image file names
image_files = labels_df['Image_name']
train_labels = labels_df['label']

all_images = []
for filename in image_files:
    image_path = os.path.join(image_dir, filename)
    image = cv2.imread(image_path)
    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    all_images.append(grayscale_image)

train_all_images = np.array(all_images)

labels_df

train_labels.shape

segment_2_0_to_2_1 = test[(test['Time'] >= 2.0) & (test['Time'] <= 2.1)]
data = test[(test['Time'] < 2.0) | (test['Time'] > 2.1)]

segment_2_0_to_2_1

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Define the number of data points per segment
start=time.time()

sampling_rate = 30
num_images = 6 * 30
store=num_images
data_points_per_segment = 120001// num_images
num_images=len(data)//data_points_per_segment
# Create an empty DataFrame for storing the labels
labels_df = pd.DataFrame(columns=['Image_name','label'])

# Define the time range for oscillation
oscillation_start_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2, unit='s')
oscillation_end_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2.2, unit='s')


# Calculate the number of segments
for i in range(num_images):
    # Extract the segment of data
    segment = data.iloc[i * data_points_per_segment: (i + 1) * data_points_per_segment]

    # Separate the current channels
    current1 = segment['current1']
    label="normal"

    image_name=f'image_{i+1}.png'
    labels_data = {'label': [label], 'Image_name': [image_name]}
    new_entry = pd.DataFrame(labels_data)
    labels_df = pd.concat([labels_df, new_entry], ignore_index=True)

    # Plot and save the image
    plt.plot(current1, 'k')
    plt.axis('off')
    plt.savefig(f'3rd/image_{i+1}.png', bbox_inches='tight', pad_inches=0)
    plt.clf()

# Print the resulting DataFrame with labels
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Define the number of data points per segment

sampling_rate = 30
num_images = 6 * 30
store=num_images
data_points_per_segment = 120001// num_images
num_images=len(segment_2_0_to_2_1)//data_points_per_segment
# Create an empty DataFrame for storing the labels
#labels_df = pd.DataFrame(columns=['Image_name','label'])

# Define the time range for oscillation
oscillation_start_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2, unit='s')
oscillation_end_time = pd.Timestamp('1970-01-01') + pd.to_timedelta(2.2, unit='s')

j=178
# Calculate the number of segments
for i in range(num_images):
    # Extract the segment of data
    segment = segment_2_0_to_2_1.iloc[i * data_points_per_segment: (i + 1) * data_points_per_segment]

    # Separate the current channels
    current1 = segment['current1']
    label="oscillated"

    image_name=f'image_{j}.png'
    labels_data = {'label': [label], 'Image_name': [image_name]}
    new_entry = pd.DataFrame(labels_data)
    labels_df = pd.concat([labels_df, new_entry], ignore_index=True)

    # Plot and save the image
    plt.plot(current1, 'k')
    plt.axis('off')
    plt.savefig(f'3rd/image_{j}.png', bbox_inches='tight', pad_inches=0)
    plt.clf()
    j+=1
# Print the resulting DataFrame with labels
print("test set seg time", time.time()-start)

print(labels_df)

import cv2
import os
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle

# Define the directory where the images are stored
image_dir = '3rd'

# Get the list of image file names
image_files = labels_df['Image_name']
test_labels = labels_df['label']

all_images = []
for filename in image_files:
    image_path = os.path.join(image_dir, filename)
    image = cv2.imread(image_path)
    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    all_images.append(grayscale_image)

test_all_images = np.array(all_images)

test_all_images.shape

test_label_counts = np.unique(test_labels, return_counts=True)
print("\nTest set label distribution:")
for label, count in zip(test_label_counts[0], test_label_counts[1]):
    print(f"Label {label}: {count} samples")

test_label_counts = np.unique(train_labels, return_counts=True)
print("\nTest set label distribution:")
for label, count in zip(test_label_counts[0], test_label_counts[1]):
    print(f"Label {label}: {count} samples")

import cv2
import os
import numpy as np
import random

# Define the directory where the images are stored
image_dir = '2nd'

# Get the list of image file names
#image_files = labels_df['Image_name']
labels = train_labels

# Create an empty array to store the resized images
resized_images = []

# Loop through each image file
for i in range(len(labels)):

    image = train_all_images[i]

    # Resize the image to 80x80 pixels
    resized_image = cv2.resize(image, (80, 80))

    # Append the resized image to the array
    resized_images.append(resized_image)

# Convert the list of resized images to a NumPy array
train_resized_images = np.array(resized_images)

# Display a randomly selected image
random_index = random.randint(0, len(train_resized_images) - 1)
random_image = train_resized_images[62]

import cv2
import os
import numpy as np
import random

# Define the directory where the images are stored
image_dir = '3rd'

# Get the list of image file names
#image_files = labels_df['Image_name']
labels = test_labels

# Create an empty array to store the resized images
resized_images = []

# Loop through each image file
for i in range(len(labels)):

    image = test_all_images[i]

    # Resize the image to 80x80 pixels
    resized_image = cv2.resize(image, (80, 80))

    # Append the resized image to the array
    resized_images.append(resized_image)

# Convert the list of resized images to a NumPy array
test_resized_images = np.array(resized_images)

# Display a randomly selected image
random_index = random.randint(0, len(test_resized_images) - 1)
random_image = test_resized_images[random_index]

test_resized_images.shape

import numpy as np
from imgaug import augmenters as iaa



# Define augmentation techniques
augmentation = iaa.Sequential([
    iaa.Fliplr(0.5),  # horizontal flips
    iaa.Affine(rotate=(-10, 10)),  # rotation
    iaa.Multiply((0.8, 1.2)),  # brightness adjustment
    iaa.GaussianBlur(sigma=(0.0, 1.0)),  # blurring
])

train_augmented_images = train_resized_images.copy()
train_augmented_labels = train_labels.tolist()  # Convert Series to list

# Iterate over each image and label in the dataset
for image, label in zip(train_resized_images, train_labels):
    # Apply augmentation to generate new samples
    if label=='oscillated':
      augmented_images_batch = augmentation(images=[image] * 250)

      # Append the augmented images to the array
      train_augmented_images = np.concatenate((train_augmented_images, augmented_images_batch))

      # Repeat the label for the corresponding augmented images
      train_augmented_labels.extend([label] * 250)
    else:
      augmented_images_batch = augmentation(images=[image] * 1)

      # Append the augmented images to the array
      train_augmented_images = np.concatenate((train_augmented_images, augmented_images_batch))

     # Repeat the label for the corresponding augmented images
      train_augmented_labels.extend([label] * 1)

train_augmented_images.shape

indices = [i for i, label in enumerate(train_augmented_labels) if label == 'oscillated']
print("Indices of oscillated values:", len(indices))

test_label_counts = np.unique(train_augmented_labels, return_counts=True)
print("\nTest set label distribution:")
for label, count in zip(test_label_counts[0], test_label_counts[1]):
    print(f"Label {label}: {count} samples")

import numpy as np
from imgaug import augmenters as iaa



# Define augmentation techniques
augmentation = iaa.Sequential([
    iaa.Fliplr(0.5),  # horizontal flips
    iaa.Affine(rotate=(-10, 10)),  # rotation
    iaa.Multiply((0.8, 1.2)),  # brightness adjustment
    iaa.GaussianBlur(sigma=(0.0, 1.0)),  # blurring
])

test_augmented_images = test_resized_images.copy()
test_augmented_labels = test_labels.tolist()  # Convert Series to list

# Iterate over each image and label in the dataset
for image, label in zip(test_resized_images, test_labels):
    # Apply augmentation to generate new samples
    if label=='oscillated':
      augmented_images_batch = augmentation(images=[image] * 100)

      # Append the augmented images to the array
      test_augmented_images = np.concatenate((test_augmented_images, augmented_images_batch))

      # Repeat the label for the corresponding augmented images
      test_augmented_labels.extend([label] * 100)
    else:
      augmented_images_batch = augmentation(images=[image] * 1)

      # Append the augmented images to the array
      test_augmented_images = np.concatenate((test_augmented_images, augmented_images_batch))

     # Repeat the label for the corresponding augmented images
      test_augmented_labels.extend([label] * 1)

import numpy as np
from imgaug import augmenters as iaa



# Define augmentation techniques
augmentation = iaa.Sequential([
    iaa.Fliplr(0.5),  # horizontal flips
    iaa.Affine(rotate=(-10, 10)),  # rotation
    iaa.Multiply((0.8, 1.2)),  # brightness adjustment
    iaa.GaussianBlur(sigma=(0.0, 1.0)),  # blurring
])

test_augmented_images = test_resized_images.copy()
test_augmented_labels = test_labels.tolist()  # Convert Series to list

# Iterate over each image and label in the dataset
for image, label in zip(test_resized_images, test_labels):
    # Apply augmentation to generate new samples
    augmented_images_batch = augmentation(images=[image] * 2)

    # Append the augmented images to the array
    test_augmented_images = np.concatenate((test_augmented_images, augmented_images_batch))

    # Repeat the label for the corresponding augmented images
    test_augmented_labels.extend([label] * 2)

test_label_counts = np.unique(test_augmented_labels, return_counts=True)
print("\nTest set label distribution:")
for label, count in zip(test_label_counts[0], test_label_counts[1]):
    print(f"Label {label}: {count} samples")

test_augmented_images.shape

train_augmented_images

from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE

# Initialize the LabelEncoder
label_encoder = LabelEncoder()

# Encode the string labels to integer values
labels_encoded = label_encoder.fit_transform(train_augmented_labels)
oversampler = SMOTE(random_state=42, k_neighbors=10)
train_augmented_images = train_augmented_images.reshape(train_augmented_images.shape[0], -1)

# Perform oversampling on the train set
train_images_oversampled, train_oversampled = oversampler.fit_resample(train_augmented_images, labels_encoded)

# Print the new label distribution after oversampling
print("Original train label distribution:", np.bincount(labels_encoded))
print("Oversampled train label distribution:", np.bincount(train_oversampled))

from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE

# Initialize the LabelEncoder
label_encoder = LabelEncoder()

# Encode the string labels to integer values
labels_encoded = label_encoder.fit_transform(test_augmented_labels)
oversampler = SMOTE(random_state=42, k_neighbors=2)
test_augmented_images = test_augmented_images.reshape(test_augmented_images.shape[0], -1)

# Perform oversampling on the train set
test_images_oversampled, test_oversampled = oversampler.fit_resample(test_augmented_images, labels_encoded)

# Print the new label distribution after oversampling
print("Original train label distribution:", np.bincount(labels_encoded))
print("Oversampled train label distribution:", np.bincount(test_oversampled))

print("Original train label distribution:", np.bincount(labels_encoded))
print("Oversampled train label distribution:", np.bincount(test_oversampled))

train_label_counts = np.unique(train_oversampled, return_counts=True)
print("Train set label distribution:")
for label, count in zip(train_label_counts[0], train_label_counts[1]):
    print(f"Label {label}: {count} samples")

# Calculate the distribution of labels in the test set
test_label_counts = np.unique(test_oversampled, return_counts=True)
print("\nTest set label distribution:")
for label, count in zip(test_label_counts[0], test_label_counts[1]):
    print(f"Label {label}: {count} samples")

import numpy as np

# Assuming you have test_files1 as the feature data for the test set (shape: [num_samples, num_features])
# Assuming you have test_labels as the label data for the test set (shape: [num_samples])

# Combine feature data and label data
train_data = np.column_stack((train_images_oversampled.reshape(train_images_oversampled.shape[0],-1), train_oversampled))

# Shuffle the test data
np.random.shuffle(train_data)


# Split shuffled data into feature data and label data
shuffled_train_files1, shuffled_train_labels = train_data[:, :-1], train_data[:, -1]

# Check the shape of the shuffled test set
print("Shuffled test set shape:", shuffled_train_files1.shape, shuffled_train_labels.shape)

import numpy as np

# Assuming you have test_files1 as the feature data for the test set (shape: [num_samples, num_features])
# Assuming you have test_labels as the label data for the test set (shape: [num_samples])

# Combine feature data and label data
test_data = np.column_stack((test_images_oversampled, test_oversampled))

# Shuffle the test data
np.random.shuffle(test_data)

# Split shuffled data into feature data and label data
shuffled_test_files, shuffled_test_labels = test_data[:, :-1], test_data[:, -1]

# Check the shape of the shuffled test set
print("Shuffled test set shape:", shuffled_test_files.shape, shuffled_test_labels.shape)

train_shuffled=shuffled_train_files1.reshape((shuffled_train_files1.shape[0],80,80))
test_shuffled=shuffled_test_files.reshape((shuffled_test_files.shape[0],80,80))

train_augmented_images=shuffled_train_files1.reshape(shuffled_train_files1.shape[0],-1)

shuffled_train_labels

np.max(train_shuffled)

# Reshape train_files to have dimensions (n_samples, n_features)
from sklearn.preprocessing import StandardScaler


# Apply standardization
scaler = StandardScaler()
train_data_scaled = scaler.fit_transform(train_shuffled.reshape(train_shuffled.shape[0],-1))

train_data_scaled.shape

test_files=shuffled_test_files.reshape(shuffled_test_files.shape[0],-1)

test_files.shape

test_data_scaled = scaler.transform(test_files)

train1 = train_data_scaled.reshape((train_data_scaled.shape[0], 80, 80))
test=test_data_scaled.reshape((test_data_scaled.shape[0],80,80))

test_labels=test_labels.reset_index()

print(shuffled_train_labels)

shuffled_test_labels

# Initialize the LabelEncoder
label_encoder = LabelEncoder()

# Encode the string labels to integer values
train_labels_encoded = label_encoder.fit_transform(shuffled_train_labels)

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from sklearn.utils import class_weight

# Initialize the model
model1 = Sequential()
model1.add(Conv2D(64, (3, 3), activation='relu', input_shape=(80, 80,1)))
model1.add(MaxPooling2D((2, 2)))
model1.add(Conv2D(32, (3, 3), activation='relu'))
model1.add(MaxPooling2D((2, 2)))
model1.add(Conv2D(32, (3, 3), activation='relu'))
model1.add(MaxPooling2D((2, 2)))
model1.add(Conv2D(16, (3, 3), activation='relu'))
model1.add(MaxPooling2D((2, 2)))
model1.add(Flatten())
model1.add(Dense(32, activation='relu'))

model1.add(Dropout(0.5))
model1.add(Dense(1, activation='sigmoid'))

# Compile the model
model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model1.summary()

import time
start_time=time.time()
model1.fit(train1, shuffled_train_labels, epochs=7, batch_size=32)
print(time.time()-start_time)

start_time=time.time()
test_predictions = model1.predict(train1)
print(time.time()-start_time)
test_predictions = np.round(test_predictions)

from sklearn.metrics import classification_report

target_names = ['0', '1']#Normal #Oscillated
print(classification_report(shuffled_train_labels, test_predictions, target_names=target_names))

# @title Default title text
start_time=time.time()
test_predictions = model1.predict(test,batch_size=1)
print(time.time()-start_time)
test_predictions = np.round(test_predictions)

from sklearn.metrics import classification_report

target_names = ['0', '1']#Normal #Oscillated
print(classification_report(shuffled_test_labels, test_predictions, target_names=target_names))

